{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c43b27-3bc2-4ed5-a950-8a69237ef15e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlime_text\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LimeTextExplainer\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# 1️⃣ Load the datasets (Modify the filenames accordingly)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m file_path_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCEAS_08.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update with actual filename\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lime'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# 1️⃣ Load the datasets (Modify the filenames accordingly)\n",
    "file_path_1 = \"CEAS_08.csv\"  # Update with actual filename\n",
    "file_path_2 = \"Phishing_Email_Analysis.csv\"  # Update with actual filename\n",
    "\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 2️⃣ Data Cleaning & Preprocessing\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    return text.strip()\n",
    "\n",
    "df[\"subject_clean\"] = df[\"subject\"].apply(clean_text)\n",
    "df[\"body_clean\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "# Combine subject and body for training\n",
    "df[\"combined_text\"] = df[\"subject_clean\"] + \" \" + df[\"body_clean\"]\n",
    "\n",
    "# 3️⃣ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"combined_text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# 4️⃣ TF-IDF Vectorization + Logistic Regression Model\n",
    "model_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),  # Convert text to numerical data\n",
    "    (\"classifier\", LogisticRegression())  # Train logistic regression model\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_pipeline, \"/mnt/data/phishing_email_model.pkl\")\n",
    "\n",
    "# 5️⃣ Evaluate the model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 6️⃣ Function for Email Prediction with Explanation\n",
    "def analyze_email(email_subject, email_body):\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "    \n",
    "    # Interpret the prediction\n",
    "    phishing_prob = confidence[1] * 100  # Percentage probability of phishing\n",
    "    legit_prob = confidence[0] * 100  # Percentage probability of legitimate\n",
    "    prediction = \"Phishing\" if phishing_prob > legit_prob else \"Legitimate\"\n",
    "    \n",
    "    # LIME Explainer for explanations\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    \n",
    "    explanation = exp.as_list()\n",
    "    \n",
    "    return {\n",
    "        \"classification\": prediction,\n",
    "        \"confidence\": phishing_prob if prediction == \"Phishing\" else legit_prob,\n",
    "        \"explanation\": explanation\n",
    "    }\n",
    "\n",
    "# 7️⃣ Test on a Sample Email\n",
    "sample_email = {\n",
    "    \"subject\": \"Urgent: Verify your bank details now!\",\n",
    "    \"body\": \"Your account has been flagged. Please verify your details immediately at http://fakebank.com/login.\"\n",
    "}\n",
    "\n",
    "result = analyze_email(sample_email[\"subject\"], sample_email[\"body\"])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092a976c-c217-48d4-b2bf-f2858ba64f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from lime) (3.10.0)\n",
      "Requirement already satisfied: numpy in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from lime) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from lime) (1.13.1)\n",
      "Requirement already satisfied: tqdm in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from lime) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from lime) (1.5.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from lime) (0.25.0)\n",
      "Requirement already satisfied: networkx>=3.0 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
      "Requirement already satisfied: pillow>=10.1 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (11.1.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (2024.12.12)\n",
      "Requirement already satisfied: packaging>=21 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (24.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-image>=0.12->lime) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from matplotlib->lime) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from matplotlib->lime) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from matplotlib->lime) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from matplotlib->lime) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from matplotlib->lime) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\codes_anaconda\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py): started\n",
      "  Building wheel for lime (setup.py): finished with status 'done'\n",
      "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283886 sha256=4a6ab40ec4b3a596862dee6f6a5e6cc78baa86bce738c5a2e3c0f3e825fa3c2b\n",
      "  Stored in directory: c:\\users\\nishant\\appdata\\local\\pip\\cache\\wheels\\85\\fa\\a3\\9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n",
      "Successfully built lime\n",
      "Installing collected packages: lime\n",
      "Successfully installed lime-0.2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c63158-5f3f-4be1-9259-7e5439860142",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/phishing_email_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m model_pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(model_pipeline, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/phishing_email_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 5️⃣ Evaluate the model\u001b[39;00m\n\u001b[0;32m     60\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/phishing_email_model.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# 1️⃣ Load the datasets (Modify the filenames accordingly)\n",
    "file_path_1 = \"CEAS_08.csv\"  # Update with actual filename\n",
    "file_path_2 = \"Phishing_Email_Analysis.csv\"  # Update with actual filename\n",
    "\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 2️⃣ Data Cleaning & Preprocessing\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    return text.strip()\n",
    "\n",
    "df[\"subject_clean\"] = df[\"subject\"].apply(clean_text)\n",
    "df[\"body_clean\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "# Combine subject and body for training\n",
    "df[\"combined_text\"] = df[\"subject_clean\"] + \" \" + df[\"body_clean\"]\n",
    "\n",
    "# 3️⃣ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"combined_text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# 4️⃣ TF-IDF Vectorization + Logistic Regression Model\n",
    "model_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),  # Convert text to numerical data\n",
    "    (\"classifier\", LogisticRegression())  # Train logistic regression model\n",
    "])\n",
    "\n",
    "# Train model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_pipeline, \"/mnt/data/phishing_email_model.pkl\")\n",
    "\n",
    "# 5️⃣ Evaluate the model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 6️⃣ Function for Email Prediction with Explanation\n",
    "def analyze_email(email_subject, email_body):\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "    \n",
    "    # Interpret the prediction\n",
    "    phishing_prob = confidence[1] * 100  # Percentage probability of phishing\n",
    "    legit_prob = confidence[0] * 100  # Percentage probability of legitimate\n",
    "    prediction = \"Phishing\" if phishing_prob > legit_prob else \"Legitimate\"\n",
    "    \n",
    "    # LIME Explainer for explanations\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    \n",
    "    explanation = exp.as_list()\n",
    "    \n",
    "    return {\n",
    "        \"classification\": prediction,\n",
    "        \"confidence\": phishing_prob if prediction == \"Phishing\" else legit_prob,\n",
    "        \"explanation\": explanation\n",
    "    }\n",
    "\n",
    "# 7️⃣ Test on a Sample Email\n",
    "sample_email = {\n",
    "    \"subject\": \"Urgent: Verify your bank details now!\",\n",
    "    \"body\": \"Your account has been flagged. Please verify your details immediately at http://fakebank.com/login.\"\n",
    "}\n",
    "\n",
    "result = analyze_email(sample_email[\"subject\"], sample_email[\"body\"])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8504fc2-ff23-44f5-9e05-c1ef4e42f916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phishing_email_model.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model in the current working directory\n",
    "joblib.dump(model_pipeline, \"phishing_email_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f09a3d8d-0b7a-43bf-9767-f315b9344bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9957859788021964\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6925\n",
      "           1       1.00      1.00      1.00      8737\n",
      "\n",
      "    accuracy                           1.00     15662\n",
      "   macro avg       1.00      1.00      1.00     15662\n",
      "weighted avg       1.00      1.00      1.00     15662\n",
      "\n",
      "\n",
      "📩 **Email Analysis Result**\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 79.58%\n",
      "🔍 Explanation:\n",
      " [('urgent', 0.07365591314642927), ('detected', -0.07138662745775409), ('account', -0.05397428018235597), ('activity', 0.031069414646774936), ('identity', -0.029319570267489138)]\n",
      "🔗 URLs Found: ['http://securebank-verify.com']\n",
      "⚠️ Suspicious URLs: ['http://securebank-verify.com']\n",
      "🚨 Flagged Words: ['urgent', 'account', 'verify']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import urllib.parse\n",
    "\n",
    "# 1️⃣ Load the datasets (Modify filenames)\n",
    "file_path_1 = \"CEAS_08.csv\"  \n",
    "file_path_2 = \"Phishing_Email_Analysis.csv\"  \n",
    "\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 2️⃣ Enhanced Data Cleaning & Preprocessing\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean email subject & body (remove URLs, punctuation, numbers, lowercase)\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    return text.strip()\n",
    "\n",
    "df[\"subject_clean\"] = df[\"subject\"].apply(clean_text)\n",
    "df[\"body_clean\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "# Combine subject and body for training\n",
    "df[\"combined_text\"] = df[\"subject_clean\"] + \" \" + df[\"body_clean\"]\n",
    "\n",
    "# 3️⃣ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"combined_text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# 4️⃣ TF-IDF Vectorization + Logistic Regression Model\n",
    "model_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),  \n",
    "    (\"classifier\", LogisticRegression(solver=\"liblinear\"))  \n",
    "])\n",
    "\n",
    "# Train model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_pipeline, \"phishing_email_model.pkl\")\n",
    "\n",
    "# 5️⃣ Evaluate the model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# 6️⃣ Enhanced Email Analysis Function\n",
    "def analyze_email(email_subject, email_body):\n",
    "    \"\"\"\n",
    "    Analyzes an email's subject & body, detects phishing, and explains why.\n",
    "    \"\"\"\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "\n",
    "    phishing_prob = confidence[1] * 100  \n",
    "    legit_prob = confidence[0] * 100  \n",
    "    prediction = \"Phishing\" if phishing_prob > legit_prob else \"Legitimate\"\n",
    "\n",
    "    # 🔍 **LIME Explainer**\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    explanation = exp.as_list()\n",
    "\n",
    "    # 🔗 **URL Analysis**\n",
    "    urls = re.findall(r'(https?://\\S+)', email_body)\n",
    "    suspicious_urls = [url for url in urls if \"bank\" in url or \"secure\" in url or \"verify\" in url]\n",
    "\n",
    "    # 🚨 **Phishing Keywords**\n",
    "    phishing_keywords = [\"verify\", \"account\", \"urgent\", \"security\", \"confirm\", \"click here\", \"suspended\"]\n",
    "    flagged_words = [word for word in input_text.split() if word in phishing_keywords]\n",
    "\n",
    "    # 📊 **Final Report**\n",
    "    result = {\n",
    "        \"Prediction\": prediction,\n",
    "        \"Confidence\": f\"{phishing_prob:.2f}%\" if prediction == \"Phishing\" else f\"{legit_prob:.2f}%\",\n",
    "        \"Explanation\": explanation,\n",
    "        \"URLs Found\": urls,\n",
    "        \"Suspicious URLs\": suspicious_urls,\n",
    "        \"Flagged Words\": flagged_words\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "# 7️⃣ **Test with Example Email**\n",
    "test_email = {\n",
    "    \"subject\": \"Urgent: Your account has been compromised!\",\n",
    "    \"body\": \"We detected suspicious activity. Please verify your identity now at http://securebank-verify.com\"\n",
    "}\n",
    "\n",
    "result = analyze_email(test_email[\"subject\"], test_email[\"body\"])\n",
    "\n",
    "print(\"\\n📩 **Email Analysis Result**\")\n",
    "print(\"📌 Prediction:\", result[\"Prediction\"])\n",
    "print(\"🎯 Confidence:\", result[\"Confidence\"])\n",
    "print(\"🔍 Explanation:\\n\", result[\"Explanation\"])\n",
    "print(\"🔗 URLs Found:\", result[\"URLs Found\"])\n",
    "print(\"⚠️ Suspicious URLs:\", result[\"Suspicious URLs\"])\n",
    "print(\"🚨 Flagged Words:\", result[\"Flagged Words\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def20d47-b8b8-4f95-a367-5f16b701d076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9957859788021964\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6925\n",
      "           1       1.00      1.00      1.00      8737\n",
      "\n",
      "    accuracy                           1.00     15662\n",
      "   macro avg       1.00      1.00      1.00     15662\n",
      "weighted avg       1.00      1.00      1.00     15662\n",
      "\n",
      "\n",
      "📩 **Email Analysis Result**\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 79.58%\n",
      "🔍 Explanation:\n",
      " [('urgent', 0.07429990012736311), ('detected', -0.07205503370305869), ('account', -0.05422252742051346), ('activity', 0.03219197837649734), ('identity', -0.028929899706333882)]\n",
      "🔗 URLs Found: ['http://securebank-verify.com']\n",
      "⚠️ Suspicious URLs: ['http://securebank-verify.com']\n",
      "🚨 Flagged Words: ['urgent', 'account', 'verify']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# 1️⃣ Load the datasets (Modify filenames)\n",
    "file_path_1 = \"CEAS_08.csv\"  \n",
    "file_path_2 = \"Phishing_Email_Analysis.csv\"  \n",
    "\n",
    "df1 = pd.read_csv(file_path_1)\n",
    "df2 = pd.read_csv(file_path_2)\n",
    "\n",
    "# Combine both datasets\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 2️⃣ Enhanced Data Cleaning & Preprocessing\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean email subject & body (remove URLs, punctuation, numbers, lowercase)\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    return text.strip()\n",
    "\n",
    "df[\"subject_clean\"] = df[\"subject\"].apply(clean_text)\n",
    "df[\"body_clean\"] = df[\"body\"].apply(clean_text)\n",
    "\n",
    "# Combine subject and body for training\n",
    "df[\"combined_text\"] = df[\"subject_clean\"] + \" \" + df[\"body_clean\"]\n",
    "\n",
    "# 3️⃣ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"combined_text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# 4️⃣ TF-IDF Vectorization + Logistic Regression Model\n",
    "model_pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=\"english\", max_features=5000)),  \n",
    "    (\"classifier\", LogisticRegression(solver=\"liblinear\"))  \n",
    "])\n",
    "\n",
    "# Train model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model_pipeline, \"phishing_email_model.pkl\")\n",
    "\n",
    "# 5️⃣ Evaluate the model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 6️⃣ Enhanced Email Analysis Function\n",
    "def analyze_email(email_subject, email_body):\n",
    "    \"\"\"\n",
    "    Analyzes an email's subject & body, detects phishing, and explains why.\n",
    "    \"\"\"\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "\n",
    "    phishing_prob = confidence[1] * 100  \n",
    "    legit_prob = confidence[0] * 100  \n",
    "    prediction = \"Phishing\" if phishing_prob > legit_prob else \"Legitimate\"\n",
    "\n",
    "    # 🔍 **LIME Explainer**\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    explanation = exp.as_list()\n",
    "\n",
    "    # 🔗 **URL Analysis**\n",
    "    urls = re.findall(r'(https?://\\S+)', email_body)\n",
    "    suspicious_urls = [url for url in urls if \"bank\" in url or \"secure\" in url or \"verify\" in url]\n",
    "\n",
    "    # 🚨 **Phishing Keywords**\n",
    "    phishing_keywords = [\"verify\", \"account\", \"urgent\", \"security\", \"confirm\", \"click here\", \"suspended\"]\n",
    "    flagged_words = [word for word in input_text.split() if word in phishing_keywords]\n",
    "\n",
    "    # 📊 **Final Report**\n",
    "    result = {\n",
    "        \"Prediction\": prediction,\n",
    "        \"Confidence\": f\"{phishing_prob:.2f}%\" if prediction == \"Phishing\" else f\"{legit_prob:.2f}%\",\n",
    "        \"Explanation\": explanation,\n",
    "        \"URLs Found\": urls,\n",
    "        \"Suspicious URLs\": suspicious_urls,\n",
    "        \"Flagged Words\": flagged_words\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "# 7️⃣ **Test with Example Email**\n",
    "test_email = {\n",
    "    \"subject\": \"Urgent: Your account has been compromised!\",\n",
    "    \"body\": \"We detected suspicious activity. Please verify your identity now at http://securebank-verify.com\"\n",
    "}\n",
    "\n",
    "result = analyze_email(test_email[\"subject\"], test_email[\"body\"])\n",
    "\n",
    "print(\"\\n📩 **Email Analysis Result**\")\n",
    "print(\"📌 Prediction:\", result[\"Prediction\"])\n",
    "print(\"🎯 Confidence:\", result[\"Confidence\"])\n",
    "print(\"🔍 Explanation:\\n\", result[\"Explanation\"])\n",
    "print(\"🔗 URLs Found:\", result[\"URLs Found\"])\n",
    "print(\"⚠️ Suspicious URLs:\", result[\"Suspicious URLs\"])\n",
    "print(\"🚨 Flagged Words:\", result[\"Flagged Words\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c81f1f1-d6f9-40f7-9500-e41d572eb991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prediction': 'Legitimate', 'Confidence': '87.56%', 'Explanation': [('test', -0.38462414944727297), ('subject', -0.15401355131437522), ('link', -0.03592320896644274), ('body', -0.01681644916830811), ('suspicious', -0.007094499498575421)], 'URLs Found': ['http://fake-url.com'], 'Suspicious URLs': [], 'Flagged Words': []}\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print raw output of one sample\n",
    "debug_result = analyze_email(\"Test Subject\", \"Test body with suspicious link http://fake-url.com\")\n",
    "print(debug_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8054d2e2-9a10-444d-ac44-bce1d0e17b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfidfVectorizer(stop_words=\"english\", max_features=5000, ngram_range=(1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3d38130-9b0e-4d4c-8e55-0eacece17bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_email(email_subject, email_body):\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "\n",
    "    phishing_prob = confidence[1] * 100  # Probability of phishing\n",
    "    legit_prob = confidence[0] * 100     # Probability of legitimate\n",
    "\n",
    "    # 👉 Adjusted threshold (default is usually 50%)\n",
    "    prediction = \"Phishing\" if phishing_prob >= 60 else \"Legitimate\"\n",
    "\n",
    "    # Explanation via LIME\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    explanation = exp.as_list()\n",
    "\n",
    "    return {\n",
    "        \"Prediction\": prediction,\n",
    "        \"Confidence\": phishing_prob if prediction == \"Phishing\" else legit_prob,\n",
    "        \"Explanation\": explanation,\n",
    "        \"URLs Found\": re.findall(r\"http[s]?://\\S+\", email_body),\n",
    "        \"Suspicious URLs\": [url for url in re.findall(r\"http[s]?://\\S+\", email_body) if \"secure\" in url or \"login\" in url],\n",
    "        \"Flagged Words\": [word for word in [\"verify\", \"login\", \"click\", \"action\", \"free\", \"reward\", \"win\"] if word in input_text]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "456392a3-bfd0-42b1-8409-dba98ea4aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Legitimate Emails\n",
    "test_emails = [\n",
    "    {\n",
    "        \"subject\": \"Your Google account security settings have been updated\",\n",
    "        \"body\": \"We've noticed a new sign-in from a known device. No action is needed if this was you. Visit https://myaccount.google.com/security for details.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Receipt from Apple\",\n",
    "        \"body\": \"Your payment for Apple Music has been processed successfully. View or manage your subscription here: https://appleid.apple.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Thanks for shopping with Amazon!\",\n",
    "        \"body\": \"Your order has been shipped and will arrive soon. You can track your package using this link: https://www.amazon.com/track-order\"\n",
    "    },\n",
    "    \n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"Immediate Action Required: Your Netflix Payment Failed\",\n",
    "        \"body\": \"We're unable to process your payment. Update your billing info at http://netflix-billing.com/update to avoid account suspension.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Security Alert: Suspicious Login Attempt Detected\",\n",
    "        \"body\": \"We have noticed suspicious activity in your bank account. Please confirm your identity now at http://securebank-verify.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Congrats! You've Won a Free iPhone 14\",\n",
    "        \"body\": \"Click now to claim your reward: http://winfreeiphone.com. This offer is only valid for 24 hours!\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b034754-b779-422d-802c-1912ae4abdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 70.04%\n",
      "🔍 Explanation:\n",
      "   - 'google' → -0.1903 (↓ legitimate)\n",
      "   - 'security' → -0.1163 (↓ legitimate)\n",
      "   - 'action' → -0.0812 (↓ legitimate)\n",
      "   - 'device' → -0.0712 (↓ legitimate)\n",
      "   - 'settings' → 0.0574 (↑ phishing)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 71.45%\n",
      "🔍 Explanation:\n",
      "   - 'payment' → 0.2916 (↑ phishing)\n",
      "   - 'music' → -0.1438 (↓ legitimate)\n",
      "   - 'subscription' → -0.1084 (↓ legitimate)\n",
      "   - 'view' → -0.0894 (↓ legitimate)\n",
      "   - 'apple' → 0.0356 (↑ phishing)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 74.13%\n",
      "🔍 Explanation:\n",
      "   - 'thanks' → -0.3796 (↓ legitimate)\n",
      "   - 'using' → -0.1505 (↓ legitimate)\n",
      "   - 'shopping' → 0.0552 (↑ phishing)\n",
      "   - 'amazon' → 0.0509 (↑ phishing)\n",
      "   - 'track' → -0.0458 (↓ legitimate)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 88.57%\n",
      "🔍 Explanation:\n",
      "   - 'payment' → 0.4082 (↑ phishing)\n",
      "   - 'failed' → -0.0913 (↓ legitimate)\n",
      "   - 'update' → -0.0617 (↓ legitimate)\n",
      "   - 'action' → -0.0425 (↓ legitimate)\n",
      "   - 'account' → -0.0323 (↓ legitimate)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 75.45%\n",
      "🔍 Explanation:\n",
      "   - 'bank' → 0.2015 (↑ phishing)\n",
      "   - 'security' → -0.0825 (↓ legitimate)\n",
      "   - 'detected' → -0.0588 (↓ legitimate)\n",
      "   - 'confirm' → -0.0561 (↓ legitimate)\n",
      "   - 'account' → -0.0441 (↓ legitimate)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 84.46%\n",
      "🔍 Explanation:\n",
      "   - 'offer' → 0.0964 (↑ phishing)\n",
      "   - 'valid' → -0.0745 (↓ legitimate)\n",
      "   - 'iphone' → -0.0590 (↓ legitimate)\n",
      "   - 'won' → 0.0522 (↑ phishing)\n",
      "   - 'free' → -0.0500 (↓ legitimate)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx, email in enumerate(test_emails):\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    \n",
    "    print(f\"📌 Prediction: {result['Prediction']}\")\n",
    "    print(f\"🎯 Confidence: {result['Confidence']:.2f}%\")\n",
    "    print(f\"🔍 Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8d289b0-251a-4110-928f-2333dc5aa27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trusted_domain_present(body):\n",
    "    trusted_domains = [\"apple.com\", \"google.com\", \"amazon.com\", \"myaccount.google.com\", \"appleid.apple.com\"]\n",
    "    urls = re.findall(r\"http[s]?://\\S+\", body)\n",
    "    return any(any(domain in url for domain in trusted_domains) for url in urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4c6e8f6-4b9d-4b39-acd8-04df9d444fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Legitimate Emails\n",
    "test_emails = [\n",
    "    {\n",
    "        \"subject\": \"Your Google account security settings have been updated\",\n",
    "        \"body\": \"We've noticed a new sign-in from a known device. No action is needed if this was you. Visit https://myaccount.google.com/security for details.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Receipt from Apple\",\n",
    "        \"body\": \"Your payment for Apple Music has been processed successfully. View or manage your subscription here: https://appleid.apple.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Thanks for shopping with Amazon!\",\n",
    "        \"body\": \"Your order has been shipped and will arrive soon. You can track your package using this link: https://www.amazon.com/track-order\"\n",
    "    },\n",
    "    \n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"Immediate Action Required: Your Netflix Payment Failed\",\n",
    "        \"body\": \"We're unable to process your payment. Update your billing info at http://netflix-billing.com/update to avoid account suspension.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Security Alert: Suspicious Login Attempt Detected\",\n",
    "        \"body\": \"We have noticed suspicious activity in your bank account. Please confirm your identity now at http://securebank-verify.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Congrats! You've Won a Free iPhone 14\",\n",
    "        \"body\": \"Click now to claim your reward: http://winfreeiphone.com. This offer is only valid for 24 hours!\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62033c7c-ed35-41f2-a3fb-1c2c47e779e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 70.04%\n",
      "🔍 Explanation:\n",
      "   - 'google' → -0.1914 (↓ legitimate)\n",
      "   - 'security' → -0.1165 (↓ legitimate)\n",
      "   - 'action' → -0.0790 (↓ legitimate)\n",
      "   - 'device' → -0.0721 (↓ legitimate)\n",
      "   - 'settings' → 0.0574 (↑ phishing)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 71.45%\n",
      "🔍 Explanation:\n",
      "   - 'payment' → 0.2909 (↑ phishing)\n",
      "   - 'music' → -0.1427 (↓ legitimate)\n",
      "   - 'subscription' → -0.1086 (↓ legitimate)\n",
      "   - 'view' → -0.0889 (↓ legitimate)\n",
      "   - 'apple' → 0.0345 (↑ phishing)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 74.13%\n",
      "🔍 Explanation:\n",
      "   - 'thanks' → -0.3795 (↓ legitimate)\n",
      "   - 'using' → -0.1492 (↓ legitimate)\n",
      "   - 'shopping' → 0.0590 (↑ phishing)\n",
      "   - 'amazon' → 0.0516 (↑ phishing)\n",
      "   - 'track' → -0.0422 (↓ legitimate)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 88.57%\n",
      "🔍 Explanation:\n",
      "   - 'payment' → 0.4096 (↑ phishing)\n",
      "   - 'failed' → -0.0910 (↓ legitimate)\n",
      "   - 'update' → -0.0606 (↓ legitimate)\n",
      "   - 'action' → -0.0417 (↓ legitimate)\n",
      "   - 'account' → -0.0282 (↓ legitimate)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 75.45%\n",
      "🔍 Explanation:\n",
      "   - 'bank' → 0.2019 (↑ phishing)\n",
      "   - 'security' → -0.0813 (↓ legitimate)\n",
      "   - 'detected' → -0.0618 (↓ legitimate)\n",
      "   - 'confirm' → -0.0565 (↓ legitimate)\n",
      "   - 'account' → -0.0473 (↓ legitimate)\n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 84.46%\n",
      "🔍 Explanation:\n",
      "   - 'offer' → 0.0961 (↑ phishing)\n",
      "   - 'valid' → -0.0738 (↓ legitimate)\n",
      "   - 'iphone' → -0.0578 (↓ legitimate)\n",
      "   - 'free' → -0.0520 (↓ legitimate)\n",
      "   - 'won' → 0.0508 (↑ phishing)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx, email in enumerate(test_emails):\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    \n",
    "    print(f\"📌 Prediction: {result['Prediction']}\")\n",
    "    print(f\"🎯 Confidence: {result['Confidence']:.2f}%\")\n",
    "    print(f\"🔍 Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b298969d-fdd6-42e3-a523-2174cf734bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trusted_domain_present(text):\n",
    "    trusted_domains = [\n",
    "        \"apple.com\", \"google.com\", \"amazon.com\", \"spotify.com\", \n",
    "        \"myaccount.google.com\", \"appleid.apple.com\", \"bbc.co.uk\", \n",
    "        \"linkedin.com\", \"twitter.com\", \"instagram.com\", \"tesco.com\"\n",
    "    ]\n",
    "    urls = re.findall(r\"http[s]?://[^\\s]+\", text)\n",
    "    return any(any(domain in url for domain in trusted_domains) for url in urls)\n",
    "\n",
    "\n",
    "def analyze_email(email_subject, email_body):\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "    \n",
    "    phishing_prob = confidence[1] * 100\n",
    "    legit_prob = confidence[0] * 100\n",
    "    prediction = \"Phishing\" if phishing_prob > legit_prob else \"Legitimate\"\n",
    "\n",
    "    # Adjust prediction if trusted domain is detected in legitimate context\n",
    "    if prediction == \"Phishing\" and trusted_domain_present(email_body):\n",
    "        if phishing_prob < 85:  # adjustable threshold\n",
    "            prediction = \"Legitimate\"\n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "\n",
    "    explanation = exp.as_list()\n",
    "    urls_found = re.findall(r\"http[s]?://[^\\s]+\", email_body)\n",
    "    flagged_urls = [url for url in urls_found if not trusted_domain_present(url)]\n",
    "    phishing_keywords = [\"urgent\", \"verify\", \"account\", \"login\", \"suspend\", \"click\", \"won\", \"free\", \"payment\"]\n",
    "\n",
    "    flagged_words = [word for word, _ in explanation if word in phishing_keywords]\n",
    "\n",
    "    return {\n",
    "        \"Prediction\": prediction,\n",
    "        \"Confidence\": f\"{phishing_prob if prediction == 'Phishing' else legit_prob:.2f}%\",\n",
    "        \"Explanation\": explanation,\n",
    "        \"URLs Found\": urls_found,\n",
    "        \"Suspicious URLs\": flagged_urls,\n",
    "        \"Flagged Words\": flagged_words,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d8183b6-bd52-4277-8c01-464b97a6f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Legitimate Emails\n",
    "test_emails = [\n",
    "    {\n",
    "        \"subject\": \"Your Google account security settings have been updated\",\n",
    "        \"body\": \"We've noticed a new sign-in from a known device. No action is needed if this was you. Visit https://myaccount.google.com/security for details.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Receipt from Apple\",\n",
    "        \"body\": \"Your payment for Apple Music has been processed successfully. View or manage your subscription here: https://appleid.apple.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Thanks for shopping with Amazon!\",\n",
    "        \"body\": \"Your order has been shipped and will arrive soon. You can track your package using this link: https://www.amazon.com/track-order\"\n",
    "    },\n",
    "    \n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"Immediate Action Required: Your Netflix Payment Failed\",\n",
    "        \"body\": \"We're unable to process your payment. Update your billing info at http://netflix-billing.com/update to avoid account suspension.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Security Alert: Suspicious Login Attempt Detected\",\n",
    "        \"body\": \"We have noticed suspicious activity in your bank account. Please confirm your identity now at http://securebank-verify.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Congrats! You've Won a Free iPhone 14\",\n",
    "        \"body\": \"Click now to claim your reward: http://winfreeiphone.com. This offer is only valid for 24 hours!\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c7af340-ed04-4420-a981-da712bd296eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_theoretical_explanation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m analyze_email(email[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m\"\u001b[39m], email[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m theory_explanation \u001b[38;5;241m=\u001b[39m generate_theoretical_explanation(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplanation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📌 Prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🎯 Confidence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_theoretical_explanation' is not defined"
     ]
    }
   ],
   "source": [
    "result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "\n",
    "print(\"📌 Prediction:\", result[\"Prediction\"])\n",
    "print(\"🎯 Confidence:\", result[\"Confidence\"])\n",
    "print(\"🔍 Keywords Explanation:\")\n",
    "for word, weight in result[\"Explanation\"]:\n",
    "    direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "    print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "\n",
    "print(\"\\n🧠 Theoretical Explanation:\")\n",
    "print(theory_explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cebc63d9-d748-43d5-91ce-e6ed1bff8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_theoretical_explanation(explanation_list):\n",
    "    phishing_terms = []\n",
    "    legit_terms = []\n",
    "\n",
    "    for word, weight in explanation_list:\n",
    "        if weight > 0:\n",
    "            phishing_terms.append(word)\n",
    "        else:\n",
    "            legit_terms.append(word)\n",
    "\n",
    "    explanation = \"This email was classified based on important words found in its content. \"\n",
    "\n",
    "    if phishing_terms:\n",
    "        explanation += (\n",
    "            f\"The presence of terms like {', '.join(phishing_terms)} contributed towards it being identified as *phishing*, \"\n",
    "            \"as these words are often associated with fraudulent activity or urgency. \"\n",
    "        )\n",
    "\n",
    "    if legit_terms:\n",
    "        explanation += (\n",
    "            f\"On the other hand, terms like {', '.join(legit_terms)} are more typical in *legitimate* communication, \"\n",
    "            \"which helped reduce suspicion. \"\n",
    "        )\n",
    "\n",
    "    if not phishing_terms and not legit_terms:\n",
    "        explanation += \"However, no strong indicative words were found, so the prediction is based on overall language patterns.\"\n",
    "\n",
    "    return explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90c48c10-e0f8-4f4a-8445-567d2b3398cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Legitimate Emails\n",
    "test_emails = [\n",
    "    {\n",
    "        \"subject\": \"Your Google account security settings have been updated\",\n",
    "        \"body\": \"We've noticed a new sign-in from a known device. No action is needed if this was you. Visit https://myaccount.google.com/security for details.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Receipt from Apple\",\n",
    "        \"body\": \"Your payment for Apple Music has been processed successfully. View or manage your subscription here: https://appleid.apple.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Thanks for shopping with Amazon!\",\n",
    "        \"body\": \"Your order has been shipped and will arrive soon. You can track your package using this link: https://www.amazon.com/track-order\"\n",
    "    },\n",
    "    \n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"Immediate Action Required: Your Netflix Payment Failed\",\n",
    "        \"body\": \"We're unable to process your payment. Update your billing info at http://netflix-billing.com/update to avoid account suspension.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Security Alert: Suspicious Login Attempt Detected\",\n",
    "        \"body\": \"We have noticed suspicious activity in your bank account. Please confirm your identity now at http://securebank-verify.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Congrats! You've Won a Free iPhone 14\",\n",
    "        \"body\": \"Click now to claim your reward: http://winfreeiphone.com. This offer is only valid for 24 hours!\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d866af5-092c-417b-b3c2-fb2065ff19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 70.04%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'google' → -0.1922 (↓ legitimate)\n",
      "   - 'security' → -0.1144 (↓ legitimate)\n",
      "   - 'action' → -0.0820 (↓ legitimate)\n",
      "   - 'device' → -0.0736 (↓ legitimate)\n",
      "   - 'settings' → 0.0580 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like settings contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like google, security, action, device are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 28.55%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.2930 (↑ phishing)\n",
      "   - 'music' → -0.1463 (↓ legitimate)\n",
      "   - 'subscription' → -0.1108 (↓ legitimate)\n",
      "   - 'view' → -0.0888 (↓ legitimate)\n",
      "   - 'apple' → 0.0372 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, apple contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like music, subscription, view are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 74.13%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thanks' → -0.3804 (↓ legitimate)\n",
      "   - 'using' → -0.1477 (↓ legitimate)\n",
      "   - 'shopping' → 0.0545 (↑ phishing)\n",
      "   - 'amazon' → 0.0503 (↑ phishing)\n",
      "   - 'track' → -0.0424 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like shopping, amazon contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thanks, using, track are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 88.57%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.4076 (↑ phishing)\n",
      "   - 'failed' → -0.0925 (↓ legitimate)\n",
      "   - 'update' → -0.0617 (↓ legitimate)\n",
      "   - 'action' → -0.0442 (↓ legitimate)\n",
      "   - 'account' → -0.0276 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like failed, update, action, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 75.45%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'bank' → 0.2001 (↑ phishing)\n",
      "   - 'security' → -0.0820 (↓ legitimate)\n",
      "   - 'detected' → -0.0598 (↓ legitimate)\n",
      "   - 'confirm' → -0.0565 (↓ legitimate)\n",
      "   - 'account' → -0.0454 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like bank contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like security, detected, confirm, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 84.46%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'offer' → 0.0962 (↑ phishing)\n",
      "   - 'valid' → -0.0761 (↓ legitimate)\n",
      "   - 'iphone' → -0.0568 (↓ legitimate)\n",
      "   - 'free' → -0.0527 (↓ legitimate)\n",
      "   - 'won' → 0.0519 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like offer, won contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like valid, iphone, free are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx, email in enumerate(test_emails):\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    \n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "\n",
    "    print(f\"📌 Prediction: {result['Prediction']}\")\n",
    "    print(f\"🎯 Confidence: {float(result['Confidence'].replace('%', '')):.2f}%\")\n",
    "    print(f\"🔍 Keywords Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "\n",
    "    print(\"\\n🧠 Theoretical Explanation:\")\n",
    "    print(theory_explanation)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3c7326e-0d8a-4042-ab13-5e3c5dfda298",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emails = [\n",
    "    # Legitimate\n",
    "    {\n",
    "        \"subject\": \"Your Receipt from Microsoft – Office 365 Annual Subscription\",\n",
    "        \"body\": \"Thank you for your purchase. Your Office 365 subscription has been renewed successfully. If you have questions, visit https://account.microsoft.com.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"University of Birmingham – Class Schedule Update\",\n",
    "        \"body\": \"Dear student, your Data Science class schedule has been updated. Please log in to your student portal at https://my.bham.ac.uk to view the changes.\"\n",
    "    },\n",
    "\n",
    "    # Phishing\n",
    "    {\n",
    "        \"subject\": \"⚠️ URGENT: Your Bank Account Will Be Locked!\",\n",
    "        \"body\": \"We noticed suspicious activity in your account. Confirm your details now at http://secure-login-verification-banking-alert.com to avoid account termination. Act now!\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"🎁 Claim Your Free iPhone 15 Pro Today!\",\n",
    "        \"body\": \"You’ve been selected to win a brand-new iPhone 15 Pro. Click here http://freeiphone-prize-now.com to claim your reward. Limited time only!\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7eb58395-0ba8-4bf5-ae21-b7b0ed6fb1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 57.74%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'subscription' → -0.2133 (↓ legitimate)\n",
      "   - 'thank' → -0.1677 (↓ legitimate)\n",
      "   - 'questions' → -0.0956 (↓ legitimate)\n",
      "   - 'microsoft' → 0.0900 (↑ phishing)\n",
      "   - 'office' → 0.0556 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like microsoft, office contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like subscription, thank, questions are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 82.87%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'schedule' → 0.2228 (↑ phishing)\n",
      "   - 'university' → -0.1765 (↓ legitimate)\n",
      "   - 'log' → -0.1323 (↓ legitimate)\n",
      "   - 'science' → -0.1302 (↓ legitimate)\n",
      "   - 'data' → -0.1282 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like schedule contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like university, log, science, data are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 85.70%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'bank' → 0.1242 (↑ phishing)\n",
      "   - 'account' → -0.0856 (↓ legitimate)\n",
      "   - 'confirm' → -0.0427 (↓ legitimate)\n",
      "   - 'urgent' → 0.0351 (↑ phishing)\n",
      "   - 'avoid' → -0.0285 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like bank, urgent contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like account, confirm, avoid are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 81.70%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'iphone' → -0.0889 (↓ legitimate)\n",
      "   - 'pro' → 0.0697 (↑ phishing)\n",
      "   - 'free' → -0.0457 (↓ legitimate)\n",
      "   - 'win' → 0.0288 (↑ phishing)\n",
      "   - 'youve' → 0.0211 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like pro, win, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like iphone, free are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for idx, email in enumerate(test_emails):\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    \n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "\n",
    "    print(f\"📌 Prediction: {result['Prediction']}\")\n",
    "    print(f\"🎯 Confidence: {float(result['Confidence'].replace('%', '')):.2f}%\")\n",
    "    print(f\"🔍 Keywords Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "\n",
    "    print(\"\\n🧠 Theoretical Explanation:\")\n",
    "    print(theory_explanation)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "beff13db-fa38-4c67-bec8-bb8b80d8baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_email(email_subject, email_body):\n",
    "    input_text = clean_text(email_subject) + \" \" + clean_text(email_body)\n",
    "    confidence = model_pipeline.predict_proba([input_text])[0]\n",
    "\n",
    "    phishing_prob = confidence[1] * 100\n",
    "    legit_prob = confidence[0] * 100\n",
    "\n",
    "    # 👇 Adjust threshold here\n",
    "    prediction = \"Phishing\" if phishing_prob >= 70 else \"Legitimate\"\n",
    "\n",
    "    # LIME explanation\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    explanation = exp.as_list()\n",
    "\n",
    "    return {\n",
    "        \"Prediction\": prediction,\n",
    "        \"Confidence\": phishing_prob if prediction == \"Phishing\" else legit_prob,\n",
    "        \"Explanation\": explanation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f36379ad-503c-4939-aa18-3040b319a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 53.16%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thank' → -0.2099 (↓ legitimate)\n",
      "   - 'way' → -0.1273 (↓ legitimate)\n",
      "   - 'order' → 0.0771 (↑ phishing)\n",
      "   - 'track' → -0.0697 (↓ legitimate)\n",
      "   - 'shopping' → 0.0352 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like order, shopping contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, way, track are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 52.08%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thanks' → -0.3917 (↓ legitimate)\n",
      "   - 'hi' → -0.1841 (↓ legitimate)\n",
      "   - 'professional' → 0.1767 (↑ phishing)\n",
      "   - 'start' → 0.0834 (↑ phishing)\n",
      "   - 'network' → 0.0524 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like professional, start, network contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thanks, hi are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 69.69%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'google' → -0.1762 (↓ legitimate)\n",
      "   - 'request' → -0.1290 (↓ legitimate)\n",
      "   - 'password' → -0.1023 (↓ legitimate)\n",
      "   - 'instructions' → 0.0630 (↑ phishing)\n",
      "   - 'account' → -0.0560 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like instructions contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like google, request, password, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 55.59%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'sent' → -0.2279 (↓ legitimate)\n",
      "   - 'view' → -0.1187 (↓ legitimate)\n",
      "   - 'transaction' → 0.1043 (↑ phishing)\n",
      "   - 'paypal' → -0.1002 (↓ legitimate)\n",
      "   - 'youve' → 0.0727 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like transaction, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like sent, view, paypal are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 95.82%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.2497 (↑ phishing)\n",
      "   - 'thank' → -0.0823 (↓ legitimate)\n",
      "   - 'premium' → 0.0333 (↑ phishing)\n",
      "   - 'account' → -0.0296 (↓ legitimate)\n",
      "   - 'confirmation' → 0.0145 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, premium, confirmation contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 43.57%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'log' → -0.1696 (↓ legitimate)\n",
      "   - 'secure' → 0.1323 (↑ phishing)\n",
      "   - 'action' → -0.0690 (↓ legitimate)\n",
      "   - 'detected' → -0.0584 (↓ legitimate)\n",
      "   - 'account' → -0.0516 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like secure contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like log, action, detected, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #7\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 33.01%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'youre' → -0.1213 (↓ legitimate)\n",
      "   - 'expires' → -0.0893 (↓ legitimate)\n",
      "   - 'ready' → 0.0549 (↑ phishing)\n",
      "   - 'tax' → -0.0399 (↓ legitimate)\n",
      "   - 'click' → 0.0389 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like ready, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like youre, expires, tax are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #8\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 73.33%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'account' → -0.0964 (↓ legitimate)\n",
      "   - 'failure' → -0.0741 (↓ legitimate)\n",
      "   - 'closed' → 0.0454 (↑ phishing)\n",
      "   - 'identity' → -0.0290 (↓ legitimate)\n",
      "   - 'click' → 0.0287 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like closed, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like account, failure, identity are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #9\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 96.18%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.1037 (↑ phishing)\n",
      "   - 'update' → -0.0424 (↓ legitimate)\n",
      "   - 'card' → 0.0298 (↑ phishing)\n",
      "   - 'immediately' → 0.0286 (↑ phishing)\n",
      "   - 'info' → -0.0118 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, card, immediately contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like update, info are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #10\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 93.22%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'pro' → 0.0215 (↑ phishing)\n",
      "   - 'won' → 0.0163 (↑ phishing)\n",
      "   - 'visiting' → -0.0157 (↓ legitimate)\n",
      "   - 'claim' → -0.0157 (↓ legitimate)\n",
      "   - 'youve' → 0.0146 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like pro, won, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like visiting, claim are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ✅ Test Emails: Legitimate + Phishing\n",
    "test_emails = [\n",
    "    # ✅ Legitimate Emails\n",
    "    {\n",
    "        \"subject\": \"Your Amazon Order Has Shipped\",\n",
    "        \"body\": \"Your recent order has been shipped and is on its way. Track your package via https://www.amazon.com/track. Thank you for shopping with us.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Welcome to LinkedIn!\",\n",
    "        \"body\": \"Hi, thanks for joining LinkedIn. Start building your professional network by connecting with others: https://www.linkedin.com/\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Google Account Recovery Request\",\n",
    "        \"body\": \"We received a request to reset your password. If this was you, follow the instructions at https://accounts.google.com to proceed.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"PayPal Transaction Receipt\",\n",
    "        \"body\": \"You've successfully sent $45 to John Smith. View details at https://www.paypal.com/myaccount.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Spotify Premium Payment Confirmation\",\n",
    "        \"body\": \"Thank you for subscribing to Spotify Premium. Your payment has been processed. Manage your account at https://www.spotify.com/account\"\n",
    "    },\n",
    "\n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"🚨 Suspicious Login Attempt – Action Needed!\",\n",
    "        \"body\": \"We've detected unusual login activity. Log in now at http://verify-login-now.com to secure your account.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Tax Refund Is Ready!\",\n",
    "        \"body\": \"You’re eligible for a £1,500 refund. Click http://gov-claim-refund-now.com to claim it before it expires.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Account Will Be Closed!\",\n",
    "        \"body\": \"Failure to verify your identity at http://bank-secure-check.com will result in account suspension. Click now.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Verify Your Netflix Billing Info Immediately\",\n",
    "        \"body\": \"We couldn’t charge your card. Update your payment information here: http://netflix-update-payment.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"You’ve Won a MacBook Pro!\",\n",
    "        \"body\": \"Claim your MacBook now by visiting http://free-macbook-promo.net. Don’t miss this opportunity!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ✅ Run the model and display results\n",
    "for idx, email in enumerate(test_emails):\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "\n",
    "    print(f\"📌 Prediction: {result['Prediction']}\")\n",
    "    try:\n",
    "        confidence = float(result[\"Confidence\"])\n",
    "    except:\n",
    "        confidence = float(result[\"Confidence\"].replace('%', ''))\n",
    "    print(f\"🎯 Confidence: {confidence:.2f}%\")\n",
    "\n",
    "    print(f\"🔍 Keywords Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "\n",
    "    print(\"\\n🧠 Theoretical Explanation:\")\n",
    "    print(theory_explanation)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b37b62a1-07b4-4502-8d1c-00417b9cfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_email(subject, body):\n",
    "    input_text = clean_text(subject) + \" \" + clean_text(body)\n",
    "    \n",
    "    # Get prediction probabilities from the model\n",
    "    probs = model_pipeline.predict_proba([input_text])[0]\n",
    "    phishing_prob = probs[1] * 100\n",
    "    legit_prob = probs[0] * 100\n",
    "    \n",
    "    # Threshold to classify as phishing (e.g., 70%)\n",
    "    prediction = \"Phishing\" if phishing_prob >= 70 else \"Legitimate\"\n",
    "    \n",
    "    # LIME for explanation\n",
    "    explainer = LimeTextExplainer(class_names=[\"Legitimate\", \"Phishing\"])\n",
    "    exp = explainer.explain_instance(input_text, model_pipeline.predict_proba, num_features=5)\n",
    "    explanation = exp.as_list()\n",
    "    \n",
    "    return {\n",
    "        \"Prediction\": prediction,\n",
    "        \"Confidence\": phishing_prob if prediction == \"Phishing\" else legit_prob,\n",
    "        \"Explanation\": explanation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8cbbb4a5-86a8-4b6b-8119-b8dd935feebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 53.16%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thank' → -0.2123 (↓ legitimate)\n",
      "   - 'way' → -0.1287 (↓ legitimate)\n",
      "   - 'order' → 0.0778 (↑ phishing)\n",
      "   - 'track' → -0.0659 (↓ legitimate)\n",
      "   - 'shopping' → 0.0365 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like order, shopping contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, way, track are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 52.08%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thanks' → -0.3915 (↓ legitimate)\n",
      "   - 'hi' → -0.1827 (↓ legitimate)\n",
      "   - 'professional' → 0.1756 (↑ phishing)\n",
      "   - 'start' → 0.0883 (↑ phishing)\n",
      "   - 'network' → 0.0538 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like professional, start, network contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thanks, hi are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 69.69%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'google' → -0.1776 (↓ legitimate)\n",
      "   - 'request' → -0.1290 (↓ legitimate)\n",
      "   - 'password' → -0.1019 (↓ legitimate)\n",
      "   - 'instructions' → 0.0635 (↑ phishing)\n",
      "   - 'account' → -0.0570 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like instructions contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like google, request, password, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 55.59%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'sent' → -0.2283 (↓ legitimate)\n",
      "   - 'view' → -0.1204 (↓ legitimate)\n",
      "   - 'transaction' → 0.1069 (↑ phishing)\n",
      "   - 'paypal' → -0.0989 (↓ legitimate)\n",
      "   - 'youve' → 0.0740 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like transaction, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like sent, view, paypal are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 95.82%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.2453 (↑ phishing)\n",
      "   - 'thank' → -0.0814 (↓ legitimate)\n",
      "   - 'premium' → 0.0321 (↑ phishing)\n",
      "   - 'account' → -0.0228 (↓ legitimate)\n",
      "   - 'confirmation' → 0.0143 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, premium, confirmation contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 43.57%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'log' → -0.1676 (↓ legitimate)\n",
      "   - 'secure' → 0.1309 (↑ phishing)\n",
      "   - 'action' → -0.0684 (↓ legitimate)\n",
      "   - 'detected' → -0.0620 (↓ legitimate)\n",
      "   - 'weve' → -0.0489 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like secure contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like log, action, detected, weve are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #7\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 33.01%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'youre' → -0.1217 (↓ legitimate)\n",
      "   - 'expires' → -0.0897 (↓ legitimate)\n",
      "   - 'ready' → 0.0554 (↑ phishing)\n",
      "   - 'click' → 0.0386 (↑ phishing)\n",
      "   - 'tax' → -0.0382 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like ready, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like youre, expires, tax are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #8\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 73.33%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'account' → -0.0962 (↓ legitimate)\n",
      "   - 'failure' → -0.0733 (↓ legitimate)\n",
      "   - 'closed' → 0.0453 (↑ phishing)\n",
      "   - 'identity' → -0.0295 (↓ legitimate)\n",
      "   - 'click' → 0.0275 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like closed, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like account, failure, identity are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #9\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 96.18%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.1043 (↑ phishing)\n",
      "   - 'update' → -0.0448 (↓ legitimate)\n",
      "   - 'card' → 0.0311 (↑ phishing)\n",
      "   - 'immediately' → 0.0284 (↑ phishing)\n",
      "   - 'information' → -0.0109 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, card, immediately contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like update, information are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #10\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 93.22%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'pro' → 0.0226 (↑ phishing)\n",
      "   - 'won' → 0.0163 (↑ phishing)\n",
      "   - 'claim' → -0.0156 (↓ legitimate)\n",
      "   - 'visiting' → -0.0154 (↓ legitimate)\n",
      "   - 'youve' → 0.0143 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like pro, won, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like claim, visiting are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ✅ Test Emails: Legitimate + Phishing\n",
    "test_emails = [\n",
    "    # ✅ Legitimate Emails\n",
    "    {\n",
    "        \"subject\": \"Your Amazon Order Has Shipped\",\n",
    "        \"body\": \"Your recent order has been shipped and is on its way. Track your package via https://www.amazon.com/track. Thank you for shopping with us.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Welcome to LinkedIn!\",\n",
    "        \"body\": \"Hi, thanks for joining LinkedIn. Start building your professional network by connecting with others: https://www.linkedin.com/\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Google Account Recovery Request\",\n",
    "        \"body\": \"We received a request to reset your password. If this was you, follow the instructions at https://accounts.google.com to proceed.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"PayPal Transaction Receipt\",\n",
    "        \"body\": \"You've successfully sent $45 to John Smith. View details at https://www.paypal.com/myaccount.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Spotify Premium Payment Confirmation\",\n",
    "        \"body\": \"Thank you for subscribing to Spotify Premium. Your payment has been processed. Manage your account at https://www.spotify.com/account\"\n",
    "    },\n",
    "\n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"🚨 Suspicious Login Attempt – Action Needed!\",\n",
    "        \"body\": \"We've detected unusual login activity. Log in now at http://verify-login-now.com to secure your account.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Tax Refund Is Ready!\",\n",
    "        \"body\": \"You’re eligible for a £1,500 refund. Click http://gov-claim-refund-now.com to claim it before it expires.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Account Will Be Closed!\",\n",
    "        \"body\": \"Failure to verify your identity at http://bank-secure-check.com will result in account suspension. Click now.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Verify Your Netflix Billing Info Immediately\",\n",
    "        \"body\": \"We couldn’t charge your card. Update your payment information here: http://netflix-update-payment.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"You’ve Won a MacBook Pro!\",\n",
    "        \"body\": \"Claim your MacBook now by visiting http://free-macbook-promo.net. Don’t miss this opportunity!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ✅ Run the model and display results\n",
    "for idx, email in enumerate(test_emails):\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "\n",
    "    print(f\"📌 Prediction: {result['Prediction']}\")\n",
    "    print(f\"🎯 Confidence: {float(result['Confidence']):.2f}%\")\n",
    "    print(f\"🔍 Keywords Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "\n",
    "    print(\"\\n🧠 Theoretical Explanation:\")\n",
    "    print(theory_explanation)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9baf0e12-e2d3-4f40-8798-988ac94e3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = \"Phishing\" if float(result[\"Confidence\"]) >= 60 else \"Legitimate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0d82e0de-c4fb-4b43-a7bc-972caeb01657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 53.16%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thank' → -0.2113 (↓ legitimate)\n",
      "   - 'way' → -0.1292 (↓ legitimate)\n",
      "   - 'order' → 0.0782 (↑ phishing)\n",
      "   - 'track' → -0.0678 (↓ legitimate)\n",
      "   - 'shopping' → 0.0381 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like order, shopping contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, way, track are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 52.08%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thanks' → -0.3910 (↓ legitimate)\n",
      "   - 'hi' → -0.1839 (↓ legitimate)\n",
      "   - 'professional' → 0.1759 (↑ phishing)\n",
      "   - 'start' → 0.0890 (↑ phishing)\n",
      "   - 'network' → 0.0552 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like professional, start, network contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thanks, hi are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 69.69%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'google' → -0.1751 (↓ legitimate)\n",
      "   - 'request' → -0.1298 (↓ legitimate)\n",
      "   - 'password' → -0.1013 (↓ legitimate)\n",
      "   - 'instructions' → 0.0608 (↑ phishing)\n",
      "   - 'account' → -0.0547 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like instructions contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like google, request, password, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 55.59%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'sent' → -0.2311 (↓ legitimate)\n",
      "   - 'view' → -0.1213 (↓ legitimate)\n",
      "   - 'transaction' → 0.1066 (↑ phishing)\n",
      "   - 'paypal' → -0.1003 (↓ legitimate)\n",
      "   - 'youve' → 0.0724 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like transaction, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like sent, view, paypal are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 95.82%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.2465 (↑ phishing)\n",
      "   - 'thank' → -0.0814 (↓ legitimate)\n",
      "   - 'premium' → 0.0336 (↑ phishing)\n",
      "   - 'account' → -0.0235 (↓ legitimate)\n",
      "   - 'confirmation' → 0.0174 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, premium, confirmation contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 43.57%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'log' → -0.1679 (↓ legitimate)\n",
      "   - 'secure' → 0.1316 (↑ phishing)\n",
      "   - 'action' → -0.0684 (↓ legitimate)\n",
      "   - 'detected' → -0.0630 (↓ legitimate)\n",
      "   - 'account' → -0.0512 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like secure contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like log, action, detected, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #7\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 33.01%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'youre' → -0.1226 (↓ legitimate)\n",
      "   - 'expires' → -0.0897 (↓ legitimate)\n",
      "   - 'ready' → 0.0551 (↑ phishing)\n",
      "   - 'tax' → -0.0388 (↓ legitimate)\n",
      "   - 'click' → 0.0386 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like ready, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like youre, expires, tax are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #8\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 73.33%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'account' → -0.0964 (↓ legitimate)\n",
      "   - 'failure' → -0.0731 (↓ legitimate)\n",
      "   - 'closed' → 0.0450 (↑ phishing)\n",
      "   - 'identity' → -0.0291 (↓ legitimate)\n",
      "   - 'click' → 0.0278 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like closed, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like account, failure, identity are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #9\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 96.18%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.1025 (↑ phishing)\n",
      "   - 'update' → -0.0438 (↓ legitimate)\n",
      "   - 'card' → 0.0295 (↑ phishing)\n",
      "   - 'immediately' → 0.0271 (↑ phishing)\n",
      "   - 'info' → -0.0121 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, card, immediately contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like update, info are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #10\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 93.22%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'pro' → 0.0217 (↑ phishing)\n",
      "   - 'won' → 0.0170 (↑ phishing)\n",
      "   - 'visiting' → -0.0164 (↓ legitimate)\n",
      "   - 'claim' → -0.0151 (↓ legitimate)\n",
      "   - 'youve' → 0.0147 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like pro, won, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like visiting, claim are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ✅ Test Emails: Legitimate + Phishing\n",
    "test_emails = [\n",
    "    # ✅ Legitimate Emails\n",
    "    {\n",
    "        \"subject\": \"Your Amazon Order Has Shipped\",\n",
    "        \"body\": \"Your recent order has been shipped and is on its way. Track your package via https://www.amazon.com/track. Thank you for shopping with us.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Welcome to LinkedIn!\",\n",
    "        \"body\": \"Hi, thanks for joining LinkedIn. Start building your professional network by connecting with others: https://www.linkedin.com/\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Google Account Recovery Request\",\n",
    "        \"body\": \"We received a request to reset your password. If this was you, follow the instructions at https://accounts.google.com to proceed.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"PayPal Transaction Receipt\",\n",
    "        \"body\": \"You've successfully sent $45 to John Smith. View details at https://www.paypal.com/myaccount.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Spotify Premium Payment Confirmation\",\n",
    "        \"body\": \"Thank you for subscribing to Spotify Premium. Your payment has been processed. Manage your account at https://www.spotify.com/account\"\n",
    "    },\n",
    "\n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"🚨 Suspicious Login Attempt – Action Needed!\",\n",
    "        \"body\": \"We've detected unusual login activity. Log in now at http://verify-login-now.com to secure your account.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Tax Refund Is Ready!\",\n",
    "        \"body\": \"You’re eligible for a £1,500 refund. Click http://gov-claim-refund-now.com to claim it before it expires.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Account Will Be Closed!\",\n",
    "        \"body\": \"Failure to verify your identity at http://bank-secure-check.com will result in account suspension. Click now.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Verify Your Netflix Billing Info Immediately\",\n",
    "        \"body\": \"We couldn’t charge your card. Update your payment information here: http://netflix-update-payment.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"You’ve Won a MacBook Pro!\",\n",
    "        \"body\": \"Claim your MacBook now by visiting http://free-macbook-promo.net. Don’t miss this opportunity!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ✅ Run the model and display results\n",
    "for idx, email in enumerate(test_emails):\n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "    \n",
    "    prediction = \"Phishing\" if float(result[\"Confidence\"]) >= 60 else \"Legitimate\"\n",
    "\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    print(f\"📌 Prediction: {prediction}\")\n",
    "    print(f\"🎯 Confidence: {float(result['Confidence']):.2f}%\")\n",
    "    print(\"🔍 Keywords Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "    print(\"\\n🧠 Theoretical Explanation:\")\n",
    "    print(theory_explanation)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "602a9973-ebe4-4f62-9ff0-680b909c0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = float(result[\"Confidence\"])\n",
    "if confidence >= 70:\n",
    "    prediction = \"Phishing\"\n",
    "elif confidence <= 30:\n",
    "    prediction = \"Legitimate\"\n",
    "else:\n",
    "    prediction = \"Uncertain\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e354cee-16ff-4023-b488-0cc10bac430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📩 Test Email #1\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 53.16%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thank' → -0.2118 (↓ legitimate)\n",
      "   - 'way' → -0.1289 (↓ legitimate)\n",
      "   - 'order' → 0.0787 (↑ phishing)\n",
      "   - 'track' → -0.0679 (↓ legitimate)\n",
      "   - 'shopping' → 0.0372 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like order, shopping contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, way, track are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #2\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 52.08%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'thanks' → -0.3904 (↓ legitimate)\n",
      "   - 'hi' → -0.1865 (↓ legitimate)\n",
      "   - 'professional' → 0.1767 (↑ phishing)\n",
      "   - 'start' → 0.0855 (↑ phishing)\n",
      "   - 'network' → 0.0519 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like professional, start, network contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thanks, hi are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #3\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 69.69%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'google' → -0.1748 (↓ legitimate)\n",
      "   - 'request' → -0.1317 (↓ legitimate)\n",
      "   - 'password' → -0.1023 (↓ legitimate)\n",
      "   - 'instructions' → 0.0604 (↑ phishing)\n",
      "   - 'account' → -0.0561 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like instructions contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like google, request, password, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #4\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 55.59%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'sent' → -0.2273 (↓ legitimate)\n",
      "   - 'view' → -0.1198 (↓ legitimate)\n",
      "   - 'transaction' → 0.1044 (↑ phishing)\n",
      "   - 'paypal' → -0.0981 (↓ legitimate)\n",
      "   - 'youve' → 0.0709 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like transaction, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like sent, view, paypal are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #5\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 95.82%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.2501 (↑ phishing)\n",
      "   - 'thank' → -0.0841 (↓ legitimate)\n",
      "   - 'premium' → 0.0352 (↑ phishing)\n",
      "   - 'account' → -0.0266 (↓ legitimate)\n",
      "   - 'confirmation' → 0.0168 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, premium, confirmation contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like thank, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #6\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 43.57%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'log' → -0.1660 (↓ legitimate)\n",
      "   - 'secure' → 0.1307 (↑ phishing)\n",
      "   - 'action' → -0.0703 (↓ legitimate)\n",
      "   - 'detected' → -0.0617 (↓ legitimate)\n",
      "   - 'account' → -0.0490 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like secure contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like log, action, detected, account are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #7\n",
      "📌 Prediction: Legitimate\n",
      "🎯 Confidence: 33.01%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'youre' → -0.1214 (↓ legitimate)\n",
      "   - 'expires' → -0.0892 (↓ legitimate)\n",
      "   - 'ready' → 0.0546 (↑ phishing)\n",
      "   - 'tax' → -0.0391 (↓ legitimate)\n",
      "   - 'click' → 0.0387 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like ready, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like youre, expires, tax are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #8\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 73.33%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'account' → -0.0961 (↓ legitimate)\n",
      "   - 'failure' → -0.0731 (↓ legitimate)\n",
      "   - 'closed' → 0.0449 (↑ phishing)\n",
      "   - 'identity' → -0.0284 (↓ legitimate)\n",
      "   - 'click' → 0.0280 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like closed, click contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like account, failure, identity are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #9\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 96.18%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'payment' → 0.1047 (↑ phishing)\n",
      "   - 'update' → -0.0437 (↓ legitimate)\n",
      "   - 'card' → 0.0297 (↑ phishing)\n",
      "   - 'immediately' → 0.0294 (↑ phishing)\n",
      "   - 'info' → -0.0137 (↓ legitimate)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like payment, card, immediately contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like update, info are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n",
      "\n",
      "📩 Test Email #10\n",
      "📌 Prediction: Phishing\n",
      "🎯 Confidence: 93.22%\n",
      "🔍 Keywords Explanation:\n",
      "   - 'pro' → 0.0217 (↑ phishing)\n",
      "   - 'won' → 0.0164 (↑ phishing)\n",
      "   - 'visiting' → -0.0159 (↓ legitimate)\n",
      "   - 'claim' → -0.0146 (↓ legitimate)\n",
      "   - 'youve' → 0.0144 (↑ phishing)\n",
      "\n",
      "🧠 Theoretical Explanation:\n",
      "This email was classified based on important words found in its content. The presence of terms like pro, won, youve contributed towards it being identified as *phishing*, as these words are often associated with fraudulent activity or urgency. On the other hand, terms like visiting, claim are more typical in *legitimate* communication, which helped reduce suspicion. \n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ✅ Test Emails: Legitimate + Phishing\n",
    "test_emails = [\n",
    "    # ✅ Legitimate Emails\n",
    "    {\n",
    "        \"subject\": \"Your Amazon Order Has Shipped\",\n",
    "        \"body\": \"Your recent order has been shipped and is on its way. Track your package via https://www.amazon.com/track. Thank you for shopping with us.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Welcome to LinkedIn!\",\n",
    "        \"body\": \"Hi, thanks for joining LinkedIn. Start building your professional network by connecting with others: https://www.linkedin.com/\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Google Account Recovery Request\",\n",
    "        \"body\": \"We received a request to reset your password. If this was you, follow the instructions at https://accounts.google.com to proceed.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"PayPal Transaction Receipt\",\n",
    "        \"body\": \"You've successfully sent $45 to John Smith. View details at https://www.paypal.com/myaccount.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Spotify Premium Payment Confirmation\",\n",
    "        \"body\": \"Thank you for subscribing to Spotify Premium. Your payment has been processed. Manage your account at https://www.spotify.com/account\"\n",
    "    },\n",
    "\n",
    "    # 🚨 Phishing Emails\n",
    "    {\n",
    "        \"subject\": \"🚨 Suspicious Login Attempt – Action Needed!\",\n",
    "        \"body\": \"We've detected unusual login activity. Log in now at http://verify-login-now.com to secure your account.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Tax Refund Is Ready!\",\n",
    "        \"body\": \"You’re eligible for a £1,500 refund. Click http://gov-claim-refund-now.com to claim it before it expires.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Your Account Will Be Closed!\",\n",
    "        \"body\": \"Failure to verify your identity at http://bank-secure-check.com will result in account suspension. Click now.\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"Verify Your Netflix Billing Info Immediately\",\n",
    "        \"body\": \"We couldn’t charge your card. Update your payment information here: http://netflix-update-payment.com\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"You’ve Won a MacBook Pro!\",\n",
    "        \"body\": \"Claim your MacBook now by visiting http://free-macbook-promo.net. Don’t miss this opportunity!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ✅ Run the model and display results\n",
    "for idx, email in enumerate(test_emails):\n",
    "    result = analyze_email(email[\"subject\"], email[\"body\"])\n",
    "    theory_explanation = generate_theoretical_explanation(result[\"Explanation\"])\n",
    "    \n",
    "    prediction = \"Phishing\" if float(result[\"Confidence\"]) >= 60 else \"Legitimate\"\n",
    "\n",
    "    print(f\"\\n📩 Test Email #{idx + 1}\")\n",
    "    print(f\"📌 Prediction: {prediction}\")\n",
    "    print(f\"🎯 Confidence: {float(result['Confidence']):.2f}%\")\n",
    "    print(\"🔍 Keywords Explanation:\")\n",
    "    for word, weight in result[\"Explanation\"]:\n",
    "        direction = \"↑ phishing\" if weight > 0 else \"↓ legitimate\"\n",
    "        print(f\"   - '{word}' → {weight:.4f} ({direction})\")\n",
    "    print(\"\\n🧠 Theoretical Explanation:\")\n",
    "    print(theory_explanation)\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82f7ad8-fd09-4fbb-a208-2a33c6b74d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'legitimate_emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCEAS_08.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# columns: 'subject', 'body'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Add labels\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m legitimate_emails[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m phishing_emails[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Merge datasets\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'legitimate_emails' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "pd.read_csv('CEAS_08.csv')  # columns: 'subject', 'body'\n",
    "\n",
    "# Add labels\n",
    "legitimate_emails['label'] = 0\n",
    "phishing_emails['label'] = 1\n",
    "\n",
    "# Merge datasets\n",
    "emails_df = pd.concat([legitimate_emails, phishing_emails]).reset_index(drop=True)\n",
    "\n",
    "# Combine subject and body\n",
    "emails_df['combined_text'] = emails_df['subject'] + ' ' + emails_df['body']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails_df['combined_text'], emails_df['label'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Function to classify new emails\n",
    "def classify_email(subject, body):\n",
    "    combined_text = subject + ' ' + body\n",
    "    vectorized_text = vectorizer.transform([combined_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    confidence_score = model.predict_proba(vectorized_text).max()\n",
    "    label = 'Phishing' if prediction == 1 else 'Legitimate'\n",
    "    return label, confidence_score\n",
    "\n",
    "# Example usage\n",
    "subject_example = \"Your Account Requires Immediate Attention\"\n",
    "body_example = \"Please click the link below to verify your account information urgently.\"\n",
    "label, confidence = classify_email(subject_example, body_example)\n",
    "print(f\"The email is {label} with {confidence*100:.2f}% confidence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c8d98a-bad4-4694-b56f-8710a85a6b93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Convert text into TF-IDF features\u001b[39;00m\n\u001b[0;32m     23\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m---> 24\u001b[0m X_train_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m     25\u001b[0m X_test_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train Logistic Regression classifier\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2104\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2098\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2099\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2100\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2101\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2102\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2103\u001b[0m )\n\u001b[1;32m-> 2104\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2106\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m             )\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1263\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1262\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1264\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:99\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     doc \u001b[38;5;241m=\u001b[39m decoder(doc)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[1;32mD:\\Codes_Anaconda\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:232\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    229\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m     )\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "emails_df = pd.read_csv('CEAS_08.csv')  # columns: 'subject', 'body', 'label'\n",
    "\n",
    "# Check for necessary columns\n",
    "assert {'subject', 'body', 'label'}.issubset(emails_df.columns), \"Dataset must contain 'subject', 'body', and 'label' columns.\"\n",
    "\n",
    "# Combine subject and body\n",
    "emails_df['combined_text'] = emails_df['subject'] + ' ' + emails_df['body']\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails_df['combined_text'], emails_df['label'], test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Function to classify new emails\n",
    "def classify_email(subject, body):\n",
    "    combined_text = subject + ' ' + body\n",
    "    vectorized_text = vectorizer.transform([combined_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    confidence_score = model.predict_proba(vectorized_text).max()\n",
    "    label = 'Phishing' if prediction == 1 else 'Legitimate'\n",
    "    return label, confidence_score\n",
    "\n",
    "# Example usage\n",
    "subject_example = \"Your Account Requires Immediate Attention\"\n",
    "body_example = \"Please click the link below to verify your account information urgently.\"\n",
    "label, confidence = classify_email(subject_example, body_example)\n",
    "print(f\"The email is {label} with {confidence*100:.2f}% confidence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5890341c-cc3d-4d50-b795-7b1260f04d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.99      0.99      0.99      4344\n",
      "    Phishing       0.99      0.99      0.99      5445\n",
      "\n",
      "    accuracy                           0.99      9789\n",
      "   macro avg       0.99      0.99      0.99      9789\n",
      "weighted avg       0.99      0.99      0.99      9789\n",
      "\n",
      "Accuracy: 0.9928491163550924\n",
      "The email is Legitimate with 89.65% confidence.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "emails_df = pd.read_csv('CEAS_08.csv')  # columns: 'subject', 'body', 'label'\n",
    "\n",
    "# Ensure required columns exist\n",
    "assert {'subject', 'body', 'label'}.issubset(emails_df.columns), \\\n",
    "    \"Dataset must contain 'subject', 'body', and 'label' columns.\"\n",
    "\n",
    "# Handle missing values by replacing NaN with empty strings\n",
    "emails_df['subject'] = emails_df['subject'].fillna('')\n",
    "emails_df['body'] = emails_df['body'].fillna('')\n",
    "\n",
    "# Combine subject and body\n",
    "emails_df['combined_text'] = emails_df['subject'] + ' ' + emails_df['body']\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails_df['combined_text'], emails_df['label'], test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Function to classify new emails\n",
    "def classify_email(subject, body):\n",
    "    combined_text = subject + ' ' + body\n",
    "    vectorized_text = vectorizer.transform([combined_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    confidence_score = model.predict_proba(vectorized_text).max()\n",
    "    label = 'Phishing' if prediction == 1 else 'Legitimate'\n",
    "    return label, confidence_score\n",
    "\n",
    "# Example usage\n",
    "subject_example = \"Meeting Agenda for Tomorrow’s Project Update\"\n",
    "body_example = \"Hi Team,I’ve attached the agenda for tomorrow’s project status meeting. We’ll discuss the current progress, upcoming deadlines, and address any questions or concerns.\"\n",
    "label, confidence = classify_email(subject_example, body_example)\n",
    "print(f\"The email is {label} with {confidence*100:.2f}% confidence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4779c245-516f-4181-a6dc-a8b92c6797d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.99      0.99      0.99      4344\n",
      "    Phishing       0.99      0.99      0.99      5445\n",
      "\n",
      "    accuracy                           0.99      9789\n",
      "   macro avg       0.99      0.99      0.99      9789\n",
      "weighted avg       0.99      0.99      0.99      9789\n",
      "\n",
      "Accuracy: 0.9928491163550924\n",
      "Subject: Meeting Agenda for Tomorrow’s Project Update\n",
      "Body: Hi Team,\n",
      "\n",
      "Attached is the agenda for tomorrow’s project meeting. We'll cover progress and upcoming deadlines.\n",
      "\n",
      "Regards, Alex.\n",
      "Classification: Legitimate (78.48% confidence)\n",
      "\n",
      "Subject: Your account will be suspended immediately!\n",
      "Body: We detected suspicious activities. Click here urgently to verify and secure your account.\n",
      "Classification: Phishing (86.75% confidence)\n",
      "\n",
      "Subject: Invoice for Your Recent Purchase\n",
      "Body: Thank you for your purchase. Please find the attached invoice for your records.\n",
      "Classification: Phishing (65.22% confidence)\n",
      "\n",
      "Subject: Action Required: Update Your Payment Information\n",
      "Body: Your billing information needs updating. Follow the link provided to avoid disruption of services.\n",
      "Classification: Phishing (78.15% confidence)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "emails_df = pd.read_csv('CEAS_08.csv')  # columns: 'subject', 'body', 'label'\n",
    "\n",
    "# Handle missing values\n",
    "emails_df['subject'] = emails_df['subject'].fillna('')\n",
    "emails_df['body'] = emails_df['body'].fillna('')\n",
    "\n",
    "# Combine subject and body\n",
    "emails_df['combined_text'] = emails_df['subject'] + ' ' + emails_df['body']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails_df['combined_text'], emails_df['label'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Function to classify new emails\n",
    "def classify_email(subject, body):\n",
    "    combined_text = subject + ' ' + body\n",
    "    vectorized_text = vectorizer.transform([combined_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    confidence_score = model.predict_proba(vectorized_text).max()\n",
    "    label = 'Phishing' if prediction == 1 else 'Legitimate'\n",
    "    return label, confidence_score\n",
    "\n",
    "# Example usage\n",
    "examples = [\n",
    "    {\"subject\": \"Meeting Agenda for Tomorrow’s Project Update\",\n",
    "     \"body\": \"Hi Team,\\n\\nAttached is the agenda for tomorrow’s project meeting. We'll cover progress and upcoming deadlines.\\n\\nRegards, Alex.\"},\n",
    "\n",
    "    {\"subject\": \"Your account will be suspended immediately!\",\n",
    "     \"body\": \"We detected suspicious activities. Click here urgently to verify and secure your account.\"},\n",
    "\n",
    "    {\"subject\": \"Invoice for Your Recent Purchase\",\n",
    "     \"body\": \"Thank you for your purchase. Please find the attached invoice for your records.\"},\n",
    "\n",
    "    {\"subject\": \"Action Required: Update Your Payment Information\",\n",
    "     \"body\": \"Your billing information needs updating. Follow the link provided to avoid disruption of services.\"}\n",
    "]\n",
    "\n",
    "for email in examples:\n",
    "    label, confidence = classify_email(email[\"subject\"], email[\"body\"])\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Body: {email['body']}\")\n",
    "    print(f\"Classification: {label} ({confidence*100:.2f}% confidence)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52ef8c8-6bc1-4643-8732-42dedf341c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.99      0.99      0.99      4344\n",
      "    Phishing       0.99      0.99      0.99      5445\n",
      "\n",
      "    accuracy                           0.99      9789\n",
      "   macro avg       0.99      0.99      0.99      9789\n",
      "weighted avg       0.99      0.99      0.99      9789\n",
      "\n",
      "Accuracy: 0.9928491163550924\n",
      "Subject: Meeting Agenda for Tomorrow’s Project Update\n",
      "Body: Hi Team,\n",
      "\n",
      "Attached is the agenda for tomorrow’s project meeting. We'll cover progress and upcoming deadlines.\n",
      "\n",
      "Regards, Alex.\n",
      "Classification: Legitimate (78.48% confidence)\n",
      "Explanation: The email appears legitimate as it contains routine and professional communication with no urgent requests or suspicious links.\n",
      "\n",
      "Subject: Your account will be suspended immediately!\n",
      "Body: We detected suspicious activities. Click here urgently to verify and secure your account.\n",
      "Classification: Phishing (86.75% confidence)\n",
      "Explanation: The email is likely phishing because it uses urgent language, requests immediate action, and may contain suspicious links.\n",
      "\n",
      "Subject: Invoice for Your Recent Purchase\n",
      "Body: Thank you for your purchase. Please find the attached invoice for your records.\n",
      "Classification: Phishing (65.22% confidence)\n",
      "Explanation: The email is likely phishing because it uses urgent language, requests immediate action, and may contain suspicious links.\n",
      "\n",
      "Subject: Action Required: Update Your Payment Information\n",
      "Body: Your billing information needs updating. Follow the link provided to avoid disruption of services.\n",
      "Classification: Phishing (78.15% confidence)\n",
      "Explanation: The email is likely phishing because it uses urgent language, requests immediate action, and may contain suspicious links.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "emails_df = pd.read_csv('CEAS_08.csv')  # columns: 'subject', 'body', 'label'\n",
    "\n",
    "# Handle missing values\n",
    "emails_df['subject'] = emails_df['subject'].fillna('')\n",
    "emails_df['body'] = emails_df['body'].fillna('')\n",
    "\n",
    "# Combine subject and body\n",
    "emails_df['combined_text'] = emails_df['subject'] + ' ' + emails_df['body']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails_df['combined_text'], emails_df['label'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Function to classify new emails\n",
    "def classify_email(subject, body):\n",
    "    combined_text = subject + ' ' + body\n",
    "    vectorized_text = vectorizer.transform([combined_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    confidence_score = model.predict_proba(vectorized_text).max()\n",
    "    label = 'Phishing' if prediction == 1 else 'Legitimate'\n",
    "    explanation = \"\"\n",
    "    if label == 'Phishing':\n",
    "        explanation = \"The email is likely phishing because it uses urgent language, requests immediate action, and may contain suspicious links.\"\n",
    "    else:\n",
    "        explanation = \"The email appears legitimate as it contains routine and professional communication with no urgent requests or suspicious links.\"\n",
    "    return label, confidence_score, explanation\n",
    "\n",
    "# Example usage\n",
    "examples = [\n",
    "    {\"subject\": \"Meeting Agenda for Tomorrow’s Project Update\",\n",
    "     \"body\": \"Hi Team,\\n\\nAttached is the agenda for tomorrow’s project meeting. We'll cover progress and upcoming deadlines.\\n\\nRegards, Alex.\"},\n",
    "\n",
    "    {\"subject\": \"Your account will be suspended immediately!\",\n",
    "     \"body\": \"We detected suspicious activities. Click here urgently to verify and secure your account.\"},\n",
    "\n",
    "    {\"subject\": \"Invoice for Your Recent Purchase\",\n",
    "     \"body\": \"Thank you for your purchase. Please find the attached invoice for your records.\"},\n",
    "\n",
    "    {\"subject\": \"Action Required: Update Your Payment Information\",\n",
    "     \"body\": \"Your billing information needs updating. Follow the link provided to avoid disruption of services.\"}\n",
    "]\n",
    "\n",
    "for email in examples:\n",
    "    label, confidence, explanation = classify_email(email[\"subject\"], email[\"body\"])\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Body: {email['body']}\")\n",
    "    print(f\"Classification: {label} ({confidence*100:.2f}% confidence)\")\n",
    "    print(f\"Explanation: {explanation}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c6b9a37-de32-447a-a41a-f66234242188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.99      0.99      0.99      4344\n",
      "    Phishing       0.99      0.99      0.99      5445\n",
      "\n",
      "    accuracy                           0.99      9789\n",
      "   macro avg       0.99      0.99      0.99      9789\n",
      "weighted avg       0.99      0.99      0.99      9789\n",
      "\n",
      "Accuracy: 0.9928491163550924\n",
      "Subject: Meeting Agenda for Tomorrow’s Project Update\n",
      "Body: Hi Team,\n",
      "\n",
      "Attached is the agenda for tomorrow’s project meeting. We'll cover progress and upcoming deadlines.\n",
      "\n",
      "Regards, Alex.\n",
      "Classification: Legitimate (78.48% confidence)\n",
      "Explanation: ✅ The email references an attachment (common in legitimate business communications).\n",
      "\n",
      "Subject: Your account will be suspended immediately!\n",
      "Body: We detected suspicious activities. Click here urgently to verify and secure your account.\n",
      "Classification: Phishing (86.75% confidence)\n",
      "Explanation: ⚠️ The email contains urgent language. ⚠️ The email requests immediate action through links. ⚠️ The email contains threatening language about account security.\n",
      "\n",
      "Subject: Invoice for Your Recent Purchase\n",
      "Body: Thank you for your purchase. Please find the attached invoice for your records.\n",
      "Classification: Phishing (65.22% confidence)\n",
      "Explanation: ✅ The email references an attachment (common in legitimate business communications).\n",
      "\n",
      "Subject: Action Required: Update Your Payment Information\n",
      "Body: Your billing information needs updating. Follow the link provided to avoid disruption of services.\n",
      "Classification: Phishing (78.15% confidence)\n",
      "Explanation: ✅ No immediate phishing indicators were found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "emails_df = pd.read_csv('CEAS_08.csv')  # columns: 'subject', 'body', 'label'\n",
    "\n",
    "# Handle missing values\n",
    "emails_df['subject'] = emails_df['subject'].fillna('')\n",
    "emails_df['body'] = emails_df['body'].fillna('')\n",
    "\n",
    "# Combine subject and body\n",
    "emails_df['combined_text'] = emails_df['subject'] + ' ' + emails_df['body']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    emails_df['combined_text'], emails_df['label'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert text into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['Legitimate', 'Phishing']))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Function to classify new emails\n",
    "def classify_email(subject, body):\n",
    "    combined_text = subject + ' ' + body\n",
    "    vectorized_text = vectorizer.transform([combined_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    confidence_score = model.predict_proba(vectorized_text).max()\n",
    "    label = 'Phishing' if prediction == 1 else 'Legitimate'\n",
    "\n",
    "    explanation = []\n",
    "    if \"urgent\" in combined_text.lower() or \"immediately\" in combined_text.lower():\n",
    "        explanation.append(\"⚠️ The email contains urgent language.\")\n",
    "    if \"verify\" in combined_text.lower() or \"click here\" in combined_text.lower():\n",
    "        explanation.append(\"⚠️ The email requests immediate action through links.\")\n",
    "    if \"invoice\" in combined_text.lower() or \"attached\" in combined_text.lower():\n",
    "        explanation.append(\"✅ The email references an attachment (common in legitimate business communications).\")\n",
    "    if \"suspended\" in combined_text.lower() or \"secure your account\" in combined_text.lower():\n",
    "        explanation.append(\"⚠️ The email contains threatening language about account security.\")\n",
    "    if not explanation:\n",
    "        explanation.append(\"✅ No immediate phishing indicators were found.\")\n",
    "\n",
    "    full_explanation = \" \".join(explanation)\n",
    "\n",
    "    return label, confidence_score, full_explanation\n",
    "\n",
    "# Example usage\n",
    "examples = [\n",
    "    {\"subject\": \"Meeting Agenda for Tomorrow’s Project Update\",\n",
    "     \"body\": \"Hi Team,\\n\\nAttached is the agenda for tomorrow’s project meeting. We'll cover progress and upcoming deadlines.\\n\\nRegards, Alex.\"},\n",
    "\n",
    "    {\"subject\": \"Your account will be suspended immediately!\",\n",
    "     \"body\": \"We detected suspicious activities. Click here urgently to verify and secure your account.\"},\n",
    "\n",
    "    {\"subject\": \"Invoice for Your Recent Purchase\",\n",
    "     \"body\": \"Thank you for your purchase. Please find the attached invoice for your records.\"},\n",
    "\n",
    "    {\"subject\": \"Action Required: Update Your Payment Information\",\n",
    "     \"body\": \"Your billing information needs updating. Follow the link provided to avoid disruption of services.\"}\n",
    "]\n",
    "\n",
    "for email in examples:\n",
    "    label, confidence, explanation = classify_email(email[\"subject\"], email[\"body\"])\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Body: {email['body']}\")\n",
    "    print(f\"Classification: {label} ({confidence*100:.2f}% confidence)\")\n",
    "    print(f\"Explanation: {explanation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcab4bb-18d1-4094-95e3-34d41494ce1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
